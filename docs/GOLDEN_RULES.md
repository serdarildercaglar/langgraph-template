# üèÜ GOLDEN RULES - LangGraph Framework Code Review (2026)

Bu dok√ºman, projenin code review s√ºrecinde kullanƒ±lacak altƒ±n kurallarƒ± tanƒ±mlar. T√ºm kurallar 2026 yƒ±lƒ± best practices ara≈ütƒ±rmasƒ±na dayanmaktadƒ±r.

---

## ƒ∞√ßindekiler

1. [LangGraph Native Yakla≈üƒ±m](#1-langgraph-native-yakla≈üƒ±m)
2. [FastAPI & Async Kurallarƒ±](#2-fastapi--async-kurallarƒ±)
3. [Python Asyncio Patterns](#3-python-asyncio-patterns)
4. [Pydantic v2 Kurallarƒ±](#4-pydantic-v2-kurallarƒ±)
5. [vLLM OpenAI-Compatible API](#5-vllm-openai-compatible-api)
6. [Milvus Vector Database](#6-milvus-vector-database)
7. [Tool Tasarƒ±mƒ±](#7-tool-tasarƒ±mƒ±)
8. [G√ºvenlik (Guardrails)](#8-g√ºvenlik-guardrails)
9. [Observability](#9-observability)
10. [Code Style](#10-code-style)

---

## 1. LangGraph Native Yakla≈üƒ±m

| Kural | A√ßƒ±klama | Kaynak |
|-------|----------|--------|
| ‚úÖ `create_react_agent` kullan | Custom ReAct loop yazma, native kullan | [LangGraph 1.0](https://www.blog.langchain.com/langchain-langgraph-1dot0/) |
| ‚úÖ Tool-based handoff | Supervisor pattern yerine sub-agent'larƒ± tool olarak tanƒ±mla | [LangGraph Design](https://www.blog.langchain.com/building-langgraph/) |
| ‚úÖ `MessagesState` (TypedDict) | Pydantic state yerine TypedDict - her update'te validation yok | [State of Agent Engineering](https://www.langchain.com/state-of-agent-engineering) |
| ‚úÖ Durable state + checkpointer | Production i√ßin persistence zorunlu (SQLite/Postgres) | [LangGraph 1.0](https://www.blog.langchain.com/langchain-langgraph-1dot0/) |
| ‚úÖ Human-in-the-loop hooks | Pre/post model hooks ile g√ºvenlik ve onay | [LangGraph 1.0](https://www.blog.langchain.com/langchain-langgraph-1dot0/) |
| ‚ùå Custom state reducers | `add_messages` reducer yeterli, custom yazma | Best Practice |

### √ñrnek: Doƒüru Agent Olu≈üturma

```python
from langgraph.prebuilt import create_react_agent
from langgraph.graph import MessagesState

# ‚úÖ Doƒüru
agent = create_react_agent(
    model=get_chat_model(),
    tools=get_all_tools(),
    prompt="You are a helpful assistant.",
    checkpointer=SqliteSaver.from_conn_string("checkpoints.db"),
)

# ‚ùå Yanlƒ±≈ü - Custom ReAct loop
class CustomAgent:
    def process(self, state):
        response = self.model.invoke(messages)
        if response.tool_calls:
            # Manuel tool handling...
```

---

## 2. FastAPI & Async Kurallarƒ±

| Kural | A√ßƒ±klama | Kaynak |
|-------|----------|--------|
| ‚úÖ `async def` + `await` I/O i√ßin | Database, API √ßaƒürƒ±larƒ± i√ßin async kullan | [FastAPI Async](https://fastapi.tiangolo.com/async/) |
| ‚úÖ `def` blocking/CPU i√ßin | CPU-bound i≈ülemleri sync fonksiyonda yap | [FastAPI Best Practices](https://github.com/zhanymkanov/fastapi-best-practices) |
| ‚ùå `async def` + blocking kod | Asla! Event loop'u bloklar | [FastAPI Async](https://fastapi.tiangolo.com/async/) |
| ‚úÖ Async DB drivers | `asyncpg`, `aiomysql`, `databases` kullan | [FastAPI Production](https://render.com/articles/fastapi-production-deployment-best-practices) |
| ‚úÖ Connection pooling | `pool_size=10`, `max_overflow=20`, `pool_pre_ping=True` | [FastAPI Production](https://render.com/articles/fastapi-production-deployment-best-practices) |
| ‚úÖ Background tasks | Uzun i≈üler i√ßin `BackgroundTasks` veya Celery | [FastAPI Production](https://render.com/articles/fastapi-production-deployment-best-practices) |
| ‚úÖ Uvicorn + Gunicorn | Dev: uvicorn, Prod: gunicorn + uvicorn workers | [FastAPI Production](https://render.com/articles/fastapi-production-deployment-best-practices) |

### √ñrnek: Async/Sync Kullanƒ±mƒ±

```python
# ‚úÖ Doƒüru - I/O bound i≈ülem async
@app.post("/chat")
async def chat(request: ChatRequest):
    result = await agent.ainvoke({"messages": request.messages})
    return result

# ‚úÖ Doƒüru - CPU bound i≈ülem sync (threadpool'da √ßalƒ±≈üƒ±r)
@app.post("/process-image")
def process_image(image: UploadFile):
    # Heavy CPU computation
    result = expensive_cpu_operation(image)
    return result

# ‚ùå Yanlƒ±≈ü - async fonksiyonda blocking √ßaƒürƒ±
@app.post("/bad-example")
async def bad_example():
    result = requests.get("https://api.example.com")  # Blocking!
    return result
```

---

## 3. Python Asyncio Patterns

| Kural | A√ßƒ±klama | Kaynak |
|-------|----------|--------|
| ‚úÖ `asyncio.run()` kullan | `run_until_complete()` yerine modern API | [Python asyncio](https://docs.python.org/3/library/asyncio.html) |
| ‚úÖ `asyncio.create_task()` + `gather()` | Paralel execution i√ßin | [Real Python](https://realpython.com/async-io-python/) |
| ‚úÖ `Semaphore` ile concurrency limit | Kaynak a≈üƒ±mƒ±nƒ± √∂nle | [Elastic Blog](https://www.elastic.co/blog/async-patterns-building-python-service) |
| ‚úÖ CPU i≈ülerini offload et | `ThreadPoolExecutor` veya `ProcessPoolExecutor` | [Python asyncio](https://docs.python.org/3/library/asyncio.html) |
| ‚úÖ Graceful shutdown | Signal handling ile temiz kapanma | [Elastic Blog](https://www.elastic.co/blog/async-patterns-building-python-service) |
| ‚ùå `await coroutine` direkt | Task'a sarmadan await event loop'a d√∂nmez | [Python asyncio](https://docs.python.org/3/library/asyncio.html) |

### √ñrnek: Paralel Execution

```python
import asyncio

# ‚úÖ Doƒüru - Paralel execution
async def fetch_all_data():
    task1 = asyncio.create_task(fetch_users())
    task2 = asyncio.create_task(fetch_orders())
    task3 = asyncio.create_task(fetch_products())

    users, orders, products = await asyncio.gather(task1, task2, task3)
    return users, orders, products

# ‚úÖ Doƒüru - Semaphore ile rate limiting
async def fetch_with_limit(urls: list[str], max_concurrent: int = 10):
    semaphore = asyncio.Semaphore(max_concurrent)

    async def fetch_one(url: str):
        async with semaphore:
            return await http_client.get(url)

    tasks = [asyncio.create_task(fetch_one(url)) for url in urls]
    return await asyncio.gather(*tasks)

# ‚ùå Yanlƒ±≈ü - Sequential execution (yava≈ü)
async def fetch_all_slow():
    users = await fetch_users()      # Bekle
    orders = await fetch_orders()    # Sonra bekle
    products = await fetch_products() # Sonra bekle
    return users, orders, products
```

---

## 4. Pydantic v2 Kurallarƒ±

| Kural | A√ßƒ±klama | Kaynak |
|-------|----------|--------|
| ‚úÖ API boundary'de Pydantic | Request/Response modelleri i√ßin | [Pydantic v2](https://pydantic.dev/articles/pydantic-v2) |
| ‚úÖ TypedDict internal state i√ßin | Agent state i√ßin Pydantic overhead'i gereksiz | Best Practice |
| ‚úÖ Declarative constraints | Python validator yerine `Field(ge=0, le=100)` | [Pydantic Performance](https://docs.pydantic.dev/latest/concepts/performance/) |
| ‚úÖ `FailFast` sequences i√ßin | Sequence validasyonunda erken √ßƒ±k (v2.8+) | [Pydantic Performance](https://docs.pydantic.dev/latest/concepts/performance/) |
| ‚úÖ TypeAdapter reuse | Her seferinde yeniden olu≈üturma (cold validation) | [Pydantic v2 at Scale](https://medium.com/@connect.hashblock/pydantic-v2-at-scale-7-tricks-for-2-faster-validation-9bd95bf27232) |
| ‚úÖ `model_validator` kullan | `root_validator` deprecated | [Pydantic Migration](https://docs.pydantic.dev/latest/migration/) |

### √ñrnek: Pydantic Kullanƒ±mƒ±

```python
from pydantic import BaseModel, Field, model_validator
from typing import Annotated, TypedDict
from langgraph.graph.message import add_messages

# ‚úÖ Doƒüru - API boundary'de Pydantic
class ChatRequest(BaseModel):
    user_id: str = Field(..., min_length=1)
    session_id: str = Field(..., min_length=1)
    messages: list[dict]
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)

    @model_validator(mode='after')
    def validate_messages(self):
        if not self.messages:
            raise ValueError("Messages cannot be empty")
        return self

# ‚úÖ Doƒüru - Internal state i√ßin TypedDict
class AgentState(TypedDict):
    messages: Annotated[list, add_messages]

# ‚ùå Yanlƒ±≈ü - Internal state i√ßin Pydantic (gereksiz overhead)
class AgentStatePydantic(BaseModel):
    messages: list  # Her update'te validation √ßalƒ±≈üƒ±r
```

---

## 5. vLLM OpenAI-Compatible API

| Kural | A√ßƒ±klama | Kaynak |
|-------|----------|--------|
| ‚úÖ `/v1/chat/completions` kullan | `/v1/completions` legacy, kullanma | [vLLM Docs](https://docs.vllm.ai/en/stable/serving/openai_compatible_server/) |
| ‚úÖ Tool calling i√ßin `--enable-auto-tool-choice` | Model desteƒüine g√∂re parser se√ß | [vLLM Docs](https://docs.vllm.ai/en/stable/serving/openai_compatible_server/) |
| ‚úÖ `gpu-memory-utilization=0.90` | Daha fazla batch i√ßin y√ºksek tut | [vLLM Quickstart](https://www.glukhov.org/post/2026/01/vllm-quickstart/) |
| ‚úÖ Streaming SSE format | OpenAI uyumlu streaming | [vLLM Docs](https://docs.vllm.ai/en/stable/serving/openai_compatible_server/) |
| ‚ö†Ô∏è Token counting farklƒ± | OpenAI ile aynƒ± olmayabilir | [vLLM Docs](https://docs.vllm.ai/en/stable/serving/openai_compatible_server/) |

### √ñrnek: vLLM Client Yapƒ±landƒ±rmasƒ±

```python
from langchain_openai import ChatOpenAI

# ‚úÖ Doƒüru - Chat completions endpoint
def get_chat_model():
    return ChatOpenAI(
        base_url=settings.vllm_base_url,  # http://localhost:8000/v1
        api_key=settings.vllm_api_key,
        model=settings.vllm_model_name,
        temperature=settings.vllm_temperature,
        max_tokens=settings.vllm_max_tokens,
        streaming=True,  # SSE streaming
    )

# vLLM server ba≈ülatma (√∂nerilen parametreler)
# python -m vllm.entrypoints.openai.api_server \
#     --model Qwen/Qwen2.5-72B-Instruct \
#     --gpu-memory-utilization 0.90 \
#     --max-model-len 8192 \
#     --enable-auto-tool-choice \
#     --tool-call-parser hermes
```

---

## 6. Milvus Vector Database

| Kural | A√ßƒ±klama | Kaynak |
|-------|----------|--------|
| ‚úÖ `AsyncMilvusClient` kullan | SDK v2 native async (**pymilvus >= 2.5.3** gerekli) | [Milvus SDK v2](https://medium.com/vector-database/introducing-milvus-sdk-v2-native-async-support-unified-apis-and-superior-performance-388c3eb6fa2d) |
| ‚úÖ `asyncio.gather()` ile batch | Paralel insert/query | [Milvus SDK v2](https://medium.com/vector-database/introducing-milvus-sdk-v2-native-async-support-unified-apis-and-superior-performance-388c3eb6fa2d) |
| ‚úÖ HNSW index | High recall, low latency | [Milvus Best Practices](https://milvus.io/ai-quick-reference/what-are-vector-database-best-practices) |
| ‚úÖ Metadata filtering | Search √∂ncesi filtrele, search space k√º√ß√ºlt | [Milvus Best Practices](https://milvus.io/ai-quick-reference/what-are-vector-database-best-practices) |
| ‚úÖ Schema Cache | ƒ∞lk fetch sonrasƒ± cache'le | [Milvus SDK v2](https://medium.com/vector-database/introducing-milvus-sdk-v2-native-async-support-unified-apis-and-superior-performance-388c3eb6fa2d) |
| ‚ö†Ô∏è SDK v1 deprecated | Milvus 3.0'da v1 desteƒüi bitecek | [Milvus SDK v2](https://medium.com/vector-database/introducing-milvus-sdk-v2-native-async-support-unified-apis-and-superior-performance-388c3eb6fa2d) |

### √ñrnek: Async Milvus Kullanƒ±mƒ±

```python
from pymilvus import AsyncMilvusClient
import asyncio

# ‚úÖ Doƒüru - Async client
async def search_vectors(queries: list[list[float]]):
    client = AsyncMilvusClient(uri="http://localhost:19530")

    # Paralel search
    tasks = [
        client.search(
            collection_name="documents",
            data=[query],
            limit=10,
            output_fields=["content", "metadata"]
        )
        for query in queries
    ]

    results = await asyncio.gather(*tasks)
    return results

# ‚úÖ Doƒüru - Batch insert
async def batch_insert(documents: list[dict]):
    client = AsyncMilvusClient(uri="http://localhost:19530")

    # Chunk'lara b√∂l ve paralel insert
    chunk_size = 1000
    chunks = [documents[i:i+chunk_size] for i in range(0, len(documents), chunk_size)]

    tasks = [client.insert("documents", chunk) for chunk in chunks]
    await asyncio.gather(*tasks)
```

---

## 7. Tool Tasarƒ±mƒ±

| Kural | A√ßƒ±klama |
|-------|----------|
| ‚úÖ Single Responsibility | Her tool tek bir i≈ü yapsƒ±n |
| ‚úÖ Docstring zorunlu | LLM tool description olarak g√∂r√ºr |
| ‚úÖ Type hints zorunlu | Schema generation i√ßin |
| ‚úÖ String return | Exception yerine hata mesajƒ± d√∂nd√ºr |
| ‚úÖ Async tercih | I/O-bound i≈ülemler i√ßin |
| ‚ùå Generic tool'lar | "do_everything" gibi tool'lar yazma |

### √ñrnek: Tool Tanƒ±mlama

```python
from tools.base import register_tool

# ‚úÖ Doƒüru - Tek sorumluluk, a√ßƒ±k docstring
@register_tool(tags=["database", "users"])
async def get_user_by_id(user_id: str) -> str:
    """Get user information by their unique ID.

    Args:
        user_id: The unique identifier of the user (e.g., "usr_12345")

    Returns:
        User information including name, email, and account status.
    """
    try:
        user = await db.users.find_one({"id": user_id})
        if not user:
            return f"User with ID '{user_id}' not found."
        return f"User: {user['name']}, Email: {user['email']}, Status: {user['status']}"
    except Exception as e:
        return f"Error retrieving user: {str(e)}"

# ‚ùå Yanlƒ±≈ü - √áok ama√ßlƒ±, belirsiz
@register_tool()
def do_database_stuff(action: str, data: dict) -> str:
    """Do various database operations."""  # √áok belirsiz!
    if action == "get":
        ...
    elif action == "create":
        ...
    elif action == "delete":
        ...
```

---

## 8. G√ºvenlik (Guardrails)

| Kural | A√ßƒ±klama |
|-------|----------|
| ‚úÖ Input validation | Prompt injection, toxic content, PII |
| ‚úÖ Output validation | Sensitive data leak kontrol√º |
| ‚úÖ Pre/post model hooks | LangGraph 1.0 native |
| ‚úÖ Rate limiting | API seviyesinde (nginx/traefik) |
| ‚úÖ Max input length | Token/karakter limiti |

### √ñrnek: Guardrail Implementasyonu

```python
from guardrails.base import GuardrailResult
import re

# ‚úÖ Input guardrail
def prompt_injection_check(content: str) -> GuardrailResult:
    """Detect potential prompt injection attempts."""
    injection_patterns = [
        r"ignore\s+(all\s+)?previous\s+instructions",
        r"disregard\s+(all\s+)?prior\s+instructions",
        r"you\s+are\s+now\s+in\s+developer\s+mode",
        r"jailbreak",
        r"DAN\s+mode",
    ]

    content_lower = content.lower()
    for pattern in injection_patterns:
        if re.search(pattern, content_lower):
            return GuardrailResult(
                passed=False,
                message="I cannot process this request.",
                triggered_rule="prompt_injection",
            )

    return GuardrailResult(passed=True)

# ‚úÖ Output guardrail
def pii_output_check(content: str) -> GuardrailResult:
    """Prevent PII leakage in responses."""
    pii_patterns = [
        r"\b\d{3}-\d{2}-\d{4}\b",  # SSN
        r"\b\d{16}\b",              # Credit card
        r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b",  # Email
    ]

    for pattern in pii_patterns:
        if re.search(pattern, content):
            return GuardrailResult(
                passed=False,
                message="Response contained sensitive information.",
                triggered_rule="pii_leak",
            )

    return GuardrailResult(passed=True)
```

---

## 9. Observability

| Kural | A√ßƒ±klama |
|-------|----------|
| ‚úÖ Langfuse tracing | T√ºm agent √ßaƒürƒ±larƒ± trace edilmeli |
| ‚úÖ External prompt management | Langfuse'dan prompt y√∂netimi |
| ‚úÖ Session/User ID zorunlu | Her request'te olmalƒ± |
| ‚úÖ Structured logging | JSON format, structlog |
| ‚úÖ p95/p99 latency monitoring | Average yerine percentile |

### √ñrnek: Observability Setup

```python
import structlog
from observability import create_trace_handler

# ‚úÖ Structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ],
)

logger = structlog.get_logger()

# ‚úÖ Langfuse tracing
async def chat_with_tracing(request: ChatRequest):
    handler = create_trace_handler(
        session_id=request.session_id,
        user_id=request.user_id,
        trace_name="chat",
        metadata={"source": request.metadata.get("source")},
    )

    logger.info(
        "chat_request_received",
        user_id=request.user_id,
        session_id=request.session_id,
        message_count=len(request.messages),
    )

    result = await agent.ainvoke(
        {"messages": request.messages},
        config={"callbacks": [handler]},
    )

    logger.info(
        "chat_request_completed",
        user_id=request.user_id,
        session_id=request.session_id,
    )

    return result
```

---

## 10. Code Style

| Kural | A√ßƒ±klama |
|-------|----------|
| ‚úÖ Type hints zorunlu | T√ºm fonksiyonlarda |
| ‚úÖ Google-style docstrings | Args, Returns, Raises |
| ‚úÖ Async-first | Sync sadece CPU-bound i√ßin |
| ‚ùå Circular imports | Mod√ºl yapƒ±sƒ±na dikkat |
| ‚ùå `Any` type | M√ºmk√ºn olduƒüunca ka√ßƒ±n |
| ‚úÖ `ruff` linting | Modern, hƒ±zlƒ± linter |

### √ñrnek: Kod Standartlarƒ±

```python
from typing import Optional
from pydantic import BaseModel

# ‚úÖ Doƒüru - Type hints, docstring, async
async def process_message(
    message: str,
    user_id: str,
    session_id: str,
    temperature: float = 0.7,
) -> dict[str, str]:
    """Process a user message and return agent response.

    Args:
        message: The user's input message.
        user_id: Unique identifier for the user.
        session_id: Current conversation session ID.
        temperature: LLM temperature setting (0.0-2.0).

    Returns:
        Dictionary containing the agent's response and metadata.

    Raises:
        ValueError: If message is empty.
        ConnectionError: If LLM service is unavailable.
    """
    if not message.strip():
        raise ValueError("Message cannot be empty")

    result = await agent.ainvoke(
        {"messages": [{"role": "user", "content": message}]},
        config={"configurable": {"thread_id": session_id}},
    )

    return {
        "content": result["messages"][-1].content,
        "session_id": session_id,
    }

# ‚ùå Yanlƒ±≈ü - Type hints yok, docstring yok
def process(msg, uid, sid, temp=0.7):
    result = agent.invoke({"messages": [{"role": "user", "content": msg}]})
    return result
```

---

## Referanslar

### LangGraph
- [LangGraph 1.0 Announcement](https://www.blog.langchain.com/langchain-langgraph-1dot0/)
- [Building LangGraph](https://www.blog.langchain.com/building-langgraph/)
- [State of Agent Engineering](https://www.langchain.com/state-of-agent-engineering)
- [Agent Orchestration 2026](https://iterathon.tech/blog/ai-agent-orchestration-frameworks-2026)

### FastAPI
- [FastAPI Async Documentation](https://fastapi.tiangolo.com/async/)
- [FastAPI Production Deployment](https://render.com/articles/fastapi-production-deployment-best-practices)
- [FastAPI Best Practices GitHub](https://github.com/zhanymkanov/fastapi-best-practices)

### Python Asyncio
- [Python asyncio Documentation](https://docs.python.org/3/library/asyncio.html)
- [Real Python Async IO](https://realpython.com/async-io-python/)
- [Elastic Async Patterns](https://www.elastic.co/blog/async-patterns-building-python-service)

### Pydantic
- [Pydantic v2 Features](https://pydantic.dev/articles/pydantic-v2)
- [Pydantic Performance](https://docs.pydantic.dev/latest/concepts/performance/)
- [Pydantic Migration Guide](https://docs.pydantic.dev/latest/migration/)

### vLLM
- [vLLM OpenAI-Compatible Server](https://docs.vllm.ai/en/stable/serving/openai_compatible_server/)
- [vLLM Quickstart 2026](https://www.glukhov.org/post/2026/01/vllm-quickstart/)

### Milvus
- [Milvus SDK v2 Async](https://medium.com/vector-database/introducing-milvus-sdk-v2-native-async-support-unified-apis-and-superior-performance-388c3eb6fa2d)
- [Milvus Best Practices](https://milvus.io/ai-quick-reference/what-are-vector-database-best-practices)
- [Milvus Documentation](https://milvus.io/docs)

---

## Versiyon Ge√ßmi≈üi

| Tarih | Versiyon | Deƒüi≈üiklikler |
|-------|----------|---------------|
| 2026-01-16 | 1.0.0 | ƒ∞lk s√ºr√ºm - 2026 best practices ara≈ütƒ±rmasƒ±na dayalƒ± |
